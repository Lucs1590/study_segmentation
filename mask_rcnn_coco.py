# -*- coding: utf-8 -*-
"""mask_rcnn_coco.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u-wuF5xlk42iMgYTQKS4ytPQRCTjDTU_

# Libraries Import
"""

!nvidia-smi

from google.colab import drive
drive.mount('/content/gdrive')

"""Mask R-CNN + COCO (Udemy)"""

!pip install --upgrade h5py==2.10.0
!pip install tensorflow==1.15.2
!pip install tensorflow-gpu==1.15.0
!pip install q keras==2.1.0
!pip install urllib3==1.26.12

import tensorflow as tf

tf.__version__

import os
import sys
import math
import json
import random

import cv2
import numpy as np
import skimage.io
import matplotlib.pyplot as plt

from google.colab.patches import cv2_imshow

"""# COCO/Dataset Processing"""

# Commented out IPython magic to ensure Python compatibility.
!mkdir coco
# %cd coco
!mkdir images
# %cd images

!wget -c http://images.cocodataset.org/zips/val2017.zip
!wget -c http://images.cocodataset.org/zips/test2017.zip

!unzip val2017.zip
!unzip test2017.zip

# %rm val2017.zip
# %rm test2017.zip

# %cd ..

!wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip
!wget -c http://images.cocodataset.org/annotations/image_info_test2017.zip

!unzip annotations_trainval2017.zip
!unzip image_info_test2017.zip

# %rm annotations_trainval2017.zip
# %rm image_info_test2017.zip
# %cd ..

"""# Evaluation Metrics"""

def run_map(dataset_validation, test_model, inference_config, names):
    APs = []
    for img_id in dataset_validation.image_ids:
        #print(img_id)
        img, img_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(
            dataset_validation,
            inference_config,
            img_id,
            use_mini_mask=False
        )

        results = test_model.detect([img], verbose=0)
        result = results[0]

        AP, precisions, recalls, overlaps = utils.compute_ap(
            gt_bbox,
            gt_class_id,
            gt_mask,
            result['rois'],
            result['class_ids'],
            result['scores'],
            result['masks']
        )
        APs.append(AP)
    return np.mean(APs)

"""# Mask R-CNN + COCO (Udemy)

## Mask R-CNN Setting
"""

!git clone https://github.com/matterport/Mask_RCNN

# Commented out IPython magic to ensure Python compatibility.
# %cd Mask_RCNN/

!python setup.py install

# Commented out IPython magic to ensure Python compatibility.
# %cd ..

ROOT_DIR = os.path.abspath('./Mask_RCNN/')
sys.path.append(ROOT_DIR)
sys.path.append(os.path.join(ROOT_DIR, 'samples/coco/'))
MODEL_DIR = os.path.join(ROOT_DIR, 'logs')
IMAGE_DIR = os.path.join(ROOT_DIR, 'images')
sys.path

from mrcnn import utils
from mrcnn import visualize
import mrcnn.model as modellib
import coco

"""## Loading the Pre-trained Neural Network"""

COCO_MODEL_PATH = os.path.join(ROOT_DIR, 'mask_rcnn_coco.h5')

COCO_MODEL_PATH

if not os.path.exists(COCO_MODEL_PATH):
  utils.download_trained_weights(COCO_MODEL_PATH)

"""## Custom Model Set Up"""

class CustomDataset(utils.Dataset):

    def load_object(self, dataset_dir, subset, annotations_file):
        """Carrega um subconjunto do dataset Balloon.
        dataset_dir: Diretorio raíz do dataset.
        subset: Subconjunto a ser carregado: train (treinamento) ou val (validação)
        """
        # Adiciona as classes. Nesse exemplo, temos apenas uma classe para adicionar.
        # self.add_class("objects", 1, "balloon")

        annotations = json.load(open(annotations_file))
        annotations = list(annotations.values())
        annotations = [annotation for annotation in annotations if annotation['regions']]

        count = 0
        for annotation in annotations:
            polygons = list(map(lambda row: row['shape_attributes'], annotation['regions']))
            # A função load_mask() vai precisar do tamanho da imagem para que possa converter os polígonos em mascaras.
            # Infelizmente, o VIA não inclui isso no JSON, então devemos ler a imagem manualmente e gerar essas máscaras.
            file_name = str(annotation['filename']).split('/')[-1]
            image_path = os.path.join(dataset_dir, file_name)
            image = skimage.io.imread(image_path)
            height, width = image.shape[:2]
            count = count+1

            self.add_image(
                "objects",
                image_id=file_name,
                path=image_path,
                width=width, height=height,
                polygons=polygons
            )
            
        print(f"Imagens {subset}: {str(count)}")

    def load_mask(self, image_id):
        """Gera as mascaras das instâncias para a imagem.
       Returna:
        masks: Uma array booleana de formato/shape [height, width, instance count] com 1 mascara por instancia.
        class_ids: uma array de 1D contendo os IDs das mascaras das instancias.
        """
        # Se não for uma imagem de conjunto de dados do balão (balloon dataset), delegue à classe ascendente.
        image_info = self.image_info[image_id]
        #print(image_info)
        if image_info["source"] != "objetos":
            return super(self.__class__, self).load_mask(image_id)

        # Converte os poligonos em uma mascara bitmap com shape  [height, width, instance_count]
        info = self.image_info[image_id]
        mask = np.zeros([info["height"], info["width"], len(info["polygons"])],
                        dtype=np.uint8)
        
        # Agora será calculado a máscara da instância. para cada pixel da imagem, classificará como pertencente à classe ou não
        for i, p in enumerate(info["polygons"]):
            # Pega os indices dos pixels dentro dos poligonos e define eles como = 1 (cor branca), caso contrário continuará valor 0 (cor preta)
            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'], mask.shape) # passamos o .shape também como 3ª parâmetro para evitar possíveis erros
            
            ## Obs: para esse dataset a anotação foi feita usando formas poligonais. 
            ## Entretanto, caso tenha usado outras formas pela ferramenta VIA (circulos e elipses) deverá especificar isso no código, ficando assim
            #if p['name'] == 'polygon':
            #  rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'], mask.shape)            
            #elif p['name'] == 'circle':
            #  rr, cc = skimage.draw.circle(p['cx'], p['cy'], p['r'])
            #else: 
            #  rr, cc = skimage.draw.ellipse(p['cx'], p['cy'], p['rx'], p['ry'], rotation=np.deg2rad(p['theta']))  

            mask[rr, cc, i] = 1

        # Retorna a mascara e a array dos IDs das classes de cada instancia. 
        # Como nesse exemplo temos uma classe apenas, retornamos uma array composta de 1s
        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)

    def image_reference(self, image_id):
        """Retorna o caminho da imagem."""
        info = self.image_info[image_id]
        if info["source"] == "objetos":
            return info["path"]
        else:
            super(self.__class__, self).image_reference(image_id)

annotation_file = '/content/gdrive/MyDrive/Projetos/colab-tests/via_coco_val.json'
dataset_path = '/content/coco/images/val2017'

from google.colab import files
files.download('/content/coco/annotations/instances_val2017.json')

from google.colab import files
files.download('/content/coco/annotations/instances_test2017.json')

dataset_val = CustomDataset()
dataset_val.load_object(dataset_path, 'val', annotation_file)
dataset_val.prepare()

"""### Inference Settings"""

class InferenceConfig(coco.CocoConfig):
  GPU_COUNT = 1
  IMAGES_PER_GPU = 1
config = InferenceConfig()

config.display()

"""## Creating the Model and Loading the Weights"""

MODEL_DIR

model = modellib.MaskRCNN(mode='inference', config=config, model_dir=MODEL_DIR)

model.load_weights(COCO_MODEL_PATH, by_name=True)

"""## Class Names Definition"""

class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',
               'bus', 'train', 'truck', 'boat', 'traffic light',
               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',
               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',
               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
               'kite', 'baseball bat', 'baseball glove', 'skateboard',
               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',
               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',
               'teddy bear', 'hair drier', 'toothbrush']

len(class_names)

"""## Prediction and Visualization"""

first = dataset.first()
first

from skimage.io import imread
img = imread(dataset.first().filepath)
plt.imshow(img);

results = model.detect([img], verbose = 1)

results

result_value = results[0]
result_value

print(result_value['class_ids'])

[class_names[x] for x in result_value['class_ids']]

visualize.display_instances(img, result_value['rois'], result_value['masks'], result_value['class_ids'], class_names, result_value['scores'])

result_value['scores']

"""### With Functions"""

imgs = dataset.take(25, seed=27)

imgs = list(map(lambda img: imread(img.filepath), imgs))

def show_imgs(images):
  for img in images:
    fig = plt.gcf()
    fig.set_size_inches(18,8)
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    plt.show()

show_imgs(imgs)

def segment_images(images):
  result_values = []
  for img in images:
    results = model.detect([img], verbose = 0)
    rv = results[0]
    visualize.display_instances(img, rv['rois'], rv['masks'], rv['class_ids'], class_names, rv['scores'])
    # print('Segments detected: ', len(rv['scores']))
    result_values.append(rv)
  return result_values

result_values = segment_images(imgs)

result_values[5]['class_ids']

"""# MASK R-CNN + COCO + BPCA"""

